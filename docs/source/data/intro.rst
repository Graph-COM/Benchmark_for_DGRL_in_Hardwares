Datasets and Tasks Overview
===========================

The DGRL-Hardware benchmark currently select 5 datasets with 13 tasks in total fronm the hardware design loop, as illustrate in the figure below:

.. image:: fig/line.pdf
   :alt: Selected Datasets and Tasks


High-Level Synthesis (HLS)
________________________

HLS is originally from `High-Level Synthesis Performance Prediction using GNNs: Benchmarking, Modeling, and Advancing <https://arxiv.org/abs/2201.06848>`_, 

After HLS front-end compilation, six node features are extracted.

Each edge has two features, the edge type represented in integers, and a binary value indicating whether this edge is a back edge.
Each graph is labeled based on its post-implementation performance metrics, which are synthesized by Vitis HLS and implemented by Vivado.
Three metrics are used for regression: DSP, LUT, and CP.
The first two are integer numbers indicating the number of resources used in the final implementation; the last one is CP timing in fractional number, determining the maximum working frequency of FPGA.
The DFG and CDFG datasets consists of 19,120 and 18,570 C programs, respectively.
The figure below shows an example C program from the CDFG dataset, with the corresponding control dataflow graph shown in the right.
More information can be found in the original paper.

.. list-table::
   :widths: 50 50
   :header-rows: 0

   * - .. image:: hls/fig/HLS_cdfg.pdf
     - .. image:: hls/fig/hls_example_program.pdf


         

Symbolic Reasoning (SR)
_______________________

SR is originally from `Gamora: Graph Learning based Symbolic Reasoning for Large-Scale Boolean Networks <https://arxiv.org/abs/2303.08256>`_, 

In this dataset, all the circuit designs are represented as and-inverter graphs (AIGs), a concise and uniform representation of BNs consisting of inverters and two-input AND gates, which allows rewriting, simulation, technology mapping, placement, and verification to share the same data structure.
In an AIG, each node has at most two incoming edges; 
a node without incoming edges is a primary input (PI);
primary outputs (POs) are denoted by special output nodes;
each internal node represents a two-input AND function. 
Based on De Morganâ€™s laws, any combinational BN can be converted into an AIG in a fast and scalable manner.

For each node, there are three node features represented in binary values denoting node types and Boolean functionality.
The first node feature indicates whether this node is a PI/PO or intermediate node (i.e., AND gate).
The second and the third node features indicate whether each input edge is inverted or not, such that AIGs can be represented as homogeneous graphs without additional edge features.

This dataset aims to leverage graph learning based approaches to accelerate the adder tree extraction in (integer) multiplier verification, which involves two reasoning steps:
(1) detecting XOR/MAJ functions to construct adders, and then (2) identifying their boundaries. 
Thus, there are two sets of node labels, i.e., two node-level classification tasks.
One task provides labels specifying whether a node (i.e., a gate) in the AIG belongs to MAJ, XOR, or is shared by both MAJ and XOR.
The other task provides labels specifying whether a node is the root node of an adder.
These AIGs and ground truth labels are generated by the logic synthesis tool ABC.
Figure below shows the AIG of an 8-bit multiplier: the blue and red nodes are the root nodes of XOR functions, with the red nodes directly connecting to the POs; the green nodes are the root nodes of MAJ functions
By pairing one XOR function with one MAJ function sharing the same set of inputs, we can extract the adder tree.
  

.. image:: fig/sr/multi8_aig.pdf

